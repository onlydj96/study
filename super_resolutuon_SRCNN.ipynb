{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Input\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "realization of evaluation index function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function for peak signal-to-noise ration (PSNR)\n",
    "def psnr(target, ref) : \n",
    "    \n",
    "    # assume RGB/BGR image\n",
    "    target_data = target.astype(float)\n",
    "    ref_data = ref.astype(float)\n",
    "    \n",
    "    diff = ref_data - target_data\n",
    "    diff = diff.flatten('C')\n",
    "    \n",
    "    rmse = math.sqrt(np.mean(diff ** 2.))\n",
    "    \n",
    "    return 20 * math.log10(255./ rmse)\n",
    "\n",
    "# define function for mean squared error (MSE)\n",
    "def mse(target, ref):\n",
    "    \n",
    "    # MSE is the sum of the squared fifference between the two the images\n",
    "    err = np.sum((target.astype('float') - ref.astype('float')) ** 2)\n",
    "    err /= float(target.shape[0] * target.shape[1])\n",
    "    \n",
    "    return err\n",
    "\n",
    "# define function that combines all three image quality metrics\n",
    "def compare_images(target, ref):\n",
    "    scores = []\n",
    "    scores.append(psnr(target, ref))\n",
    "    scores.append(mse(target, ref))\n",
    "    scores.append(ssim(target, ref, multichannel= True))\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare degraded images by introducing quality distortions via resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_images(path, factor):\n",
    "    \n",
    "    # loop through the file in the directory \n",
    "    for file in os.listdir(path):\n",
    "        \n",
    "        # open the file\n",
    "        img = cv2.imread(path + '/' + file)\n",
    "        \n",
    "        # find old and new image dimensions\n",
    "        h, w, c = img.shape\n",
    "        new_height = int(h / factor)\n",
    "        new_width = int(w / factor)\n",
    "        \n",
    "        # resize the image - down\n",
    "        img = cv2.resize(img, (new_width, new_height), interpolation = cv2.INTER_LINEAR)\n",
    "        \n",
    "        # resize the image - up\n",
    "        img = cv2.resize(img, (w, h), interpolation = cv2.INTER_LINEAR)\n",
    "        \n",
    "        # save the image\n",
    "        print('Saving {}'.format(file))\n",
    "        cv2.imwrite('images/{}'.format(file), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving baboon.bmp\n",
      "Saving baby_GT.bmp\n",
      "Saving barbara.bmp\n",
      "Saving bird_GT.bmp\n",
      "Saving bridge.bmp\n",
      "Saving butterfly_GT.bmp\n",
      "Saving coastguard.bmp\n",
      "Saving comic.bmp\n",
      "Saving face.bmp\n",
      "Saving flowers.bmp\n",
      "Saving foreman.bmp\n",
      "Saving head_GT.bmp\n",
      "Saving lenna.bmp\n",
      "Saving man.bmp\n",
      "Saving monarch.bmp\n",
      "Saving pepper.bmp\n",
      "Saving ppt3.bmp\n",
      "Saving woman_GT.bmp\n",
      "Saving zebra.bmp\n"
     ]
    }
   ],
   "source": [
    "prepare_images('D:/Personal Project/source/', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baboon.bmp\n",
      "PSNR: 22.157084083442548\n",
      "SSIM: 1187.1161333333334\n",
      "\n",
      "baby_GT.bmp\n",
      "PSNR: 34.37180640966199\n",
      "SSIM: 71.28874588012695\n",
      "\n",
      "barbara.bmp\n",
      "PSNR: 25.906629837568126\n",
      "SSIM: 500.65508535879627\n",
      "\n",
      "bird_GT.bmp\n",
      "PSNR: 32.896644728720005\n",
      "SSIM: 100.12375819830247\n",
      "\n",
      "bridge.bmp\n",
      "PSNR: 25.850528790115554\n",
      "SSIM: 507.1643714904785\n",
      "\n",
      "butterfly_GT.bmp\n",
      "PSNR: 24.782076560337416\n",
      "SSIM: 648.6254119873047\n",
      "\n",
      "coastguard.bmp\n",
      "PSNR: 27.161600663887082\n",
      "SSIM: 375.00887784090907\n",
      "\n",
      "comic.bmp\n",
      "PSNR: 23.799861502225532\n",
      "SSIM: 813.2338836565096\n",
      "\n",
      "face.bmp\n",
      "PSNR: 30.99220650287191\n",
      "SSIM: 155.23189718546524\n",
      "\n",
      "flowers.bmp\n",
      "PSNR: 27.454504805386147\n",
      "SSIM: 350.55093922651935\n",
      "\n",
      "foreman.bmp\n",
      "PSNR: 30.14456532664372\n",
      "SSIM: 188.6883483270202\n",
      "\n",
      "head_GT.bmp\n",
      "PSNR: 31.020502848237534\n",
      "SSIM: 154.2237755102041\n",
      "\n",
      "lenna.bmp\n",
      "PSNR: 31.47349297867539\n",
      "SSIM: 138.94800567626953\n",
      "\n",
      "man.bmp\n",
      "PSNR: 27.22646369798821\n",
      "SSIM: 369.4496383666992\n",
      "\n",
      "monarch.bmp\n",
      "PSNR: 30.196242365288896\n",
      "SSIM: 186.45643615722656\n",
      "\n",
      "pepper.bmp\n",
      "PSNR: 29.88947161686106\n",
      "SSIM: 200.1033935546875\n",
      "\n",
      "ppt3.bmp\n",
      "PSNR: 24.84926168950471\n",
      "SSIM: 638.6684263912582\n",
      "\n",
      "woman_GT.bmp\n",
      "PSNR: 29.326236280817465\n",
      "SSIM: 227.812729498164\n",
      "\n",
      "zebra.bmp\n",
      "PSNR: 27.909840639329513\n",
      "SSIM: 315.6585459528818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir('images/'):\n",
    "    \n",
    "    # open target and reference images\n",
    "    target = cv2.imread('images/{}'.format(file))\n",
    "    ref = cv2.imread('source/{}'.format(file))\n",
    "    \n",
    "    # calculate the scores\n",
    "    scores = compare_images(target, ref)\n",
    "    \n",
    "    # print a;; three scores\n",
    "    print('{}\\nPSNR: {}\\nSSIM: {}\\n'.format(file, scores[0], scores[1], scores[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the SRCNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    \n",
    "    # define model type\n",
    "    SRCNN = Sequential()\n",
    "    \n",
    "    # add model layers\n",
    "    SRCNN.add(Conv2D(filters=128, kernel_size=(9, 9), kernel_initializer='glorot_uniform',\n",
    "                     activation='relu', padding='valid', use_bias=True, input_shape=(None, None, 1)))\n",
    "    SRCNN.add(Conv2D(filters=64, kernel_size=(3, 3), kernel_initializer='glorot_uniform',\n",
    "                     activation='relu', padding='same', use_bias=True))\n",
    "    SRCNN.add(Conv2D(filters=1, kernel_size=(5,5), kernel_initializer='glorot_uniform',\n",
    "                     activation='linear', padding='valid', use_bias=True))\n",
    "    \n",
    "    # compile model\n",
    "    SRCNN.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "    \n",
    "    return SRCNN\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define necessary image processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modcrop(img, scale):\n",
    "    tmpsz = img.shape\n",
    "    sz = tmpsz[0:2]\n",
    "    sz = sz - np.mod(sz, scale)\n",
    "    img = img[0:sz[0], 1:sz[1]]\n",
    "    return img\n",
    "\n",
    "def shave(image, border):\n",
    "    img = image[border:-border, border:-border]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define main prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_path):\n",
    "    \n",
    "    # load the SRCNN model with weights\n",
    "    srcnn = model()\n",
    "    srcnn.load_weights('3051crop_weight_200.h5')\n",
    "    \n",
    "    # load the degraded and reference images\n",
    "    path, file = os.path.split(image_path)\n",
    "    degraded = cv2.imread(image_path)\n",
    "    ref = cv2.imread('source/{}'.format(file))\n",
    "    \n",
    "    # preprocess the image with madcrop\n",
    "    ref = modcrop(ref, 3)\n",
    "    degraded = modcrop(degraded, 3)\n",
    "    \n",
    "    # convert the image to VCrCb - (srccn trained on Y channel)\n",
    "    temp = cv2.cvtColor(degraded, cv2.COLOR_BGR2YCrCb)\n",
    "    \n",
    "    # create image slice and normalize\n",
    "    Y = np.zeros((1, temp.shape[0], temp.shape[1], 1), dtype=float)\n",
    "    Y[0, :, :, 0] = temp[:, :, 0].astype(float) / 255\n",
    "    \n",
    "    # perform super-resolution with srcnn\n",
    "    pre = srcnn.predict(Y, batch_size=1)\n",
    "    \n",
    "    # post-process output\n",
    "    pre *= 255\n",
    "    pre[pre[:] > 255] = 255\n",
    "    pre[pre[:] < 0] = 0\n",
    "    pre = pre.astype(np.uint8)\n",
    "    \n",
    "    # copy Y channel back to image and convert to BGR\n",
    "    temp = shave(temp, 6)\n",
    "    temp[:, :, 0] = pre[0, :, :, 0]\n",
    "    output = cv2.cvtColor(temp, cv2.COLOR_YCrCb2BGR) \n",
    "    \n",
    "    # remove border from reference and degraded image\n",
    "    ref = shave(ref.astype(np.uint8), 6)\n",
    "    degraded = shave(degraded.astype(np.uint8), 6)\n",
    "    \n",
    "    # image quality caluclations \n",
    "    scores = []\n",
    "    scores.append(compare_images(degraded, ref))\n",
    "    scores.append(compare_images(output, ref))\n",
    "    \n",
    "    # return images and scores\n",
    "    return ref, degraded, output, scores  \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (356,493) into shape (348,485)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12604/3185444357.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mref\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdegraded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'images/flowers.bmp'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# print all scores for all images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Degraded Image : \\nPSNR: {}\\nMSE: {}\\nSSIM: {}\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Reconstructed Image : \\nPSNR: {}\\nMSE: {}\\nSSIM: {}\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12604/477834074.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;31m# copy Y channel back to image and convert to BGR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mtemp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpre\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_YCrCb2BGR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (356,493) into shape (348,485)"
     ]
    }
   ],
   "source": [
    "ref, degraded, output, scores = predict('images/flowers.bmp')\n",
    "\n",
    "# print all scores for all images\n",
    "print('Degraded Image : \\nPSNR: {}\\nMSE: {}\\nSSIM: {}\\n'.format(scores[0][0], scores[0][1], scores[0][2]))\n",
    "print('Reconstructed Image : \\nPSNR: {}\\nMSE: {}\\nSSIM: {}\\n'.format(scores[1][0], scores[1][1], scores[1][2]))\n",
    "\n",
    "# display images as subplots\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20,8))\n",
    "axs[0].imshow(cv2.cvtColor(ref, cv2.COLOR_BGR2RGB))\n",
    "axs[0].set_title(\"Original\")\n",
    "axs[1].imshow(cv2.cvtColor(degraded, cv2.COLOR_BGR2RGB))\n",
    "axs[1].set_title(\"Degraded\")\n",
    "axs[2].imshow(cv2.cvtColor(output, cv2.COLOR_BGR2RGB))\n",
    "axs[2].set_title(\"SRCNN\")\n",
    "\n",
    "# remove the x and y tick marks\n",
    "for ax in axs:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
