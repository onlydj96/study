{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention Mechanism\n",
    "===================\n",
    "   - seq2seq 모델의 문제점을 개선\n",
    "      1. 하나의 고정 길이 벡터에 모든 정보를 압축해 정보 손실 발생\n",
    "      2. RNN의 문제점인 기울기 소실(Gradient vanising)이 동일하게 발생\n",
    "\n",
    "   - seq2seq 문제를 개선하기 위해 Attention Machanism이 탄생\n",
    "       - Attention Mechanism은 디코더가 예측하는 시점마다 인코더의 전체 입력 문장을 다시 한번 참조\n",
    "       - 이때 전체 입력 문장을 단순히 참조하지 않고, 예측할 단어와 연관이 있는 단어를 집중(Attention)해서 참조"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Attention Mechanism 종류__\n",
    "   - attention mechanism에는 스코어 계산 방식의 차이에 따라 다양한 종류가 존재\n",
    "   - dot, scaled dot, general, concat, kocation-base\n",
    "   - 용어 정리\n",
    "      1. s : querys(t 시점에서의 디코더 셀의 은닉상태)\n",
    "      2. h : keys(모든 시점의 인코더 셀 은닉상태)\n",
    "      3. W : 학습 가능한 가중치 행렬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Attention Mechanism 과정__\n",
    "   - Attention Mechanism 중 가장 기초적인 dot-product attention을 예제로 적용 가정을 학습\n",
    "   - Attention Mechanism 과정\n",
    "      1. Attention score 계산\n",
    "      2. softmax 함수를 통한 attention distribution 계산\n",
    "      3. 각 인코더의 어텐션 가중치와 은닉 상태를 가중합하여 어텐션 값 계산\n",
    "      4. 어텐션 값과 디코더의 t 시점의 은닉 상태를 연결\n",
    "      5. 출력층 연산의 입력이 되는 s 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__데이터 전처리__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input, Embedding, LSTM\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import urllib3\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas 형식으로 불러오기\n",
    "lines = pd.read_csv(\"./nlp_data/fra.txt\", names=['src', 'tar', 'lic'], sep='\\t')\n",
    "del lines['lic']\n",
    "\n",
    "lines = lines.loc[:, 'src':'tar']\n",
    "lines = lines[0:60000]\n",
    "lines.tar = lines.tar.apply(lambda x: '\\t' + x + '\\n')\n",
    "\n",
    "src_vocab = set()\n",
    "for line in lines.src:\n",
    "    for char in line:\n",
    "        src_vocab.add(char)\n",
    "\n",
    "tar_vocab = set()\n",
    "for line in lines.tar:\n",
    "    for char in line:\n",
    "        tar_vocab.add(char)\n",
    "        \n",
    "src_vocab = sorted(list(src_vocab))\n",
    "tar_vocab = sorted(list(tar_vocab))\n",
    "\n",
    "src_vocab_size = len(src_vocab) + 1\n",
    "tar_vocab_size = len(tar_vocab) + 1\n",
    "\n",
    "src_to_idx = dict([(word, i+1) for i, word in enumerate(src_vocab)])\n",
    "tar_to_idx = dict([(word, i+1) for i, word in enumerate(tar_vocab)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder input\n",
    "\n",
    "encoder_input = []\n",
    "for line in lines.src:\n",
    "    encoder_input.append([src_to_idx[w] for w in line])\n",
    "    \n",
    "# Decoder input\n",
    "\n",
    "decoder_input = []\n",
    "for line in lines.tar:\n",
    "    decoder_input.append([tar_to_idx[w] for w in line])\n",
    "    \n",
    "# Decoder target\n",
    "\n",
    "decoder_target = []\n",
    "for line in lines.tar:\n",
    "    decoder_target.append([tar_to_idx[w] for w in line if w != '\\t'])\n",
    "    \n",
    "# padding\n",
    "# 문장 최대길이\n",
    "max_src_len = max([len(line) for line in lines.src])\n",
    "max_tar_len = max([len(line) for line in lines.tar])\n",
    "\n",
    "encoder_input = pad_sequences(encoder_input, maxlen=max_src_len, padding='post')\n",
    "decoder_input = pad_sequences(decoder_input, maxlen=max_tar_len, padding='post')\n",
    "decoder_target = pad_sequences(decoder_target, maxlen=max_tar_len, padding='post')\n",
    "\n",
    "# one-hot encoding\n",
    "encoder_input = to_categorical(encoder_input)\n",
    "decoder_input = to_categorical(decoder_input)\n",
    "decoder_target = to_categorical(decoder_target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Attention Mechanism 모델__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인코더(Encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None, src_vocab_size))\n",
    "encoder_lstm = LSTM(256, return_state=True)\n",
    "\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "디코터(Decoder)\n",
    "   - 디코더에서는 seq2seq와는 다르게 attention layer를 추가함\n",
    "   - S_는 은닉 상태와 디코더의 최종 출력을 연결한 결과, 연결할 때 형상을 맞춰주기 위해 축을 추가함\n",
    "   - attention layer는 디코더의 은닉 상태와 인코더 은닉 상태 전체를 받아 컨텍스트 벡터를 생성함\n",
    "   - 이 때 attention layer는 앞서 설명한 과정 중 1~3번째를 수행, 나머지는 사용자가 연결해주어야 함\n",
    "   - 마지막으로 생성한 컨텍스트 벡터와 디코더의 은닉 상태 전체를 이어 softmax layer에 투입, 인덱스를 예측함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Attention\n",
    "\n",
    "\n",
    "decoder_inputs = Input(shape=(None, tar_vocab_size))\n",
    "decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "\n",
    "S_ = tf.concat([state_h[:, tf.newaxis, :], decoder_outputs[:, :-1, :]], axis=1)\n",
    "\n",
    "attention = Attention()\n",
    "context_vector = attention([S_, encoder_outputs])\n",
    "concat = tf.concat([decoder_outputs, context_vector], axis=-1)\n",
    "decoder_softmax_layer = Dense(tar_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 구성 및 학습\n",
    "   - 구성하는 방법은 seq2seq와 동일함\n",
    "   - attention mechanism을 활용해 학습 시간이 절반 가량 준 것을 확인할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "375/375 [==============================] - 14s 28ms/step - loss: 0.8960 - val_loss: 0.7975\n",
      "Epoch 2/25\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.5515 - val_loss: 0.6452\n",
      "Epoch 3/25\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 0.4561 - val_loss: 0.5706\n",
      "Epoch 4/25\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.4039 - val_loss: 0.5259\n",
      "Epoch 5/25\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 0.3673 - val_loss: 0.4988\n",
      "Epoch 6/25\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 0.3399 - val_loss: 0.4719\n",
      "Epoch 7/25\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.3194 - val_loss: 0.4495\n",
      "Epoch 8/25\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 0.3032 - val_loss: 0.4375\n",
      "Epoch 9/25\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.2898 - val_loss: 0.4275\n",
      "Epoch 10/25\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.2789 - val_loss: 0.4214\n",
      "Epoch 11/25\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.2689 - val_loss: 0.4115\n",
      "Epoch 12/25\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.2606 - val_loss: 0.4080\n",
      "Epoch 13/25\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.2528 - val_loss: 0.4064\n",
      "Epoch 14/25\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.2461 - val_loss: 0.3982\n",
      "Epoch 15/25\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.2398 - val_loss: 0.3972\n",
      "Epoch 16/25\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.2341 - val_loss: 0.3953\n",
      "Epoch 17/25\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.2288 - val_loss: 0.3939\n",
      "Epoch 18/25\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.2240 - val_loss: 0.3911\n",
      "Epoch 19/25\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.2193 - val_loss: 0.3915\n",
      "Epoch 20/25\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.2149 - val_loss: 0.3921\n",
      "Epoch 21/25\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.2108 - val_loss: 0.3895\n",
      "Epoch 22/25\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.2069 - val_loss: 0.3916\n",
      "Epoch 23/25\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.2031 - val_loss: 0.3920\n",
      "Epoch 24/25\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.1996 - val_loss: 0.3922\n",
      "Epoch 25/25\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.1962 - val_loss: 0.3930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17fb49f6888>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[encoder_input, decoder_input], y=decoder_target,\n",
    "          batch_size=128,\n",
    "          epochs=25,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예측\n",
    "   - 예측도 seq2seq와 동일하나, 추가된 모델 구조를 반영해주어야 함(attention layer)\n",
    "   - encoder와 decoder를 분리해주었기 때문에 decoder에서 encoder의 은닉상태(estate_h)와 최종 은닉 상태(encoder_outputs)를 따로 입력받아야 함\n",
    "   - 나머지는 seq2seq에서 작성한 부분과 동일함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(inputs=encoder_inputs, \n",
    "                      outputs=[encoder_outputs, encoder_states])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_state_input_h = Input(shape=(256))\n",
    "decoder_state_input_c = Input(shape=(256))\n",
    "\n",
    "estate_h = Input(shape=(256))\n",
    "encoder_outputs - Input(shape=(256))\n",
    "\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "\n",
    "decoder_states = [state_h, state_c]\n",
    "\n",
    "S_ = tf.concat([estate_h[:, tf.newaxis, :], decoder_outputs[:, :-1, :]], axis=1)\n",
    "context_vector = attention([S_, encoder_outputs])\n",
    "decoder_concat = tf.concat([decoder_outputs, context_vector], axis=1)\n",
    "\n",
    "decoder_outputs = decoder_softmax_layer(decoder_concat)\n",
    "decoder_model = Model(inputs=[decoder_inputs, estate_h, encoder_outputs] + decoder_states_inputs,\n",
    "                      outputs=[decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_src = dict((i, char) for char, i in src_to_idx.items())\n",
    "idx_to_tar = dict((i, char) for char, i in tar_to_idx.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_decode(input_seq):\n",
    "    outputs_input, states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    target_seq = np.zeros((1, 1, tar_vocab_size))\n",
    "    target_seq[0, 0, tar_to_idx['\\t']] = 1\n",
    "    \n",
    "    stop = False\n",
    "    decoded_sentence = \"\"\n",
    "    \n",
    "    while not stop:\n",
    "         output_tokens, h, c = decoder_model.predict([target_seq, states_value[0], outputs_input] + states_value)\n",
    "         \n",
    "         sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "         sampled_char = idx_to_tar[sampled_token_index]\n",
    "         decoded_sentence += sampled_char\n",
    "         \n",
    "         if sampled_char == '\\n' or len(decoded_sentence) > max_tar_len:\n",
    "             stop = True\n",
    "             \n",
    "         target_seq = np.zeros((1, 1, tar_vocab_size))\n",
    "         target_seq[0, 0, sampled_token_index] = 1\n",
    "         \n",
    "         states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\ProgramData\\Anaconda3\\envs\\py37\\lib\\site-packages\\keras\\engine\\training.py\", line 1621, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\ProgramData\\Anaconda3\\envs\\py37\\lib\\site-packages\\keras\\engine\\training.py\", line 1611, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\ProgramData\\Anaconda3\\envs\\py37\\lib\\site-packages\\keras\\engine\\training.py\", line 1604, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\ProgramData\\Anaconda3\\envs\\py37\\lib\\site-packages\\keras\\engine\\training.py\", line 1572, in predict_step\n        return self(x, training=False)\n    File \"C:\\ProgramData\\Anaconda3\\envs\\py37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\ProgramData\\Anaconda3\\envs\\py37\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 248, in assert_input_compatibility\n        f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Exception encountered when calling layer \"model_2\" (type Functional).\n    \n    Input 0 of layer \"dense\" is incompatible with the layer: expected axis -1of input shape to have value 512, but received input with shape (None, 2, 256)\n    \n    Call arguments received:\n      • inputs=('tf.Tensor(shape=(None, 1, 105), dtype=float32)', 'tf.Tensor(shape=(None, 256), dtype=float32)', 'tf.Tensor(shape=(None, 256), dtype=float32)', 'tf.Tensor(shape=(None, 256), dtype=float32)', 'tf.Tensor(shape=(None, 256), dtype=float32)')\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7908/2587725509.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mseq_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0minput_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_input\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mseq_index\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mseq_index\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mdecoded_sentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"입력 : \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mseq_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7908/2445666554.py\u001b[0m in \u001b[0;36mpredict_decode\u001b[1;34m(input_seq)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m          \u001b[0moutput_tokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget_seq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates_value\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs_input\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstates_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m          \u001b[0msampled_token_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tokens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\py37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1127\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1129\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1130\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\ProgramData\\Anaconda3\\envs\\py37\\lib\\site-packages\\keras\\engine\\training.py\", line 1621, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\ProgramData\\Anaconda3\\envs\\py37\\lib\\site-packages\\keras\\engine\\training.py\", line 1611, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\ProgramData\\Anaconda3\\envs\\py37\\lib\\site-packages\\keras\\engine\\training.py\", line 1604, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\ProgramData\\Anaconda3\\envs\\py37\\lib\\site-packages\\keras\\engine\\training.py\", line 1572, in predict_step\n        return self(x, training=False)\n    File \"C:\\ProgramData\\Anaconda3\\envs\\py37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\ProgramData\\Anaconda3\\envs\\py37\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 248, in assert_input_compatibility\n        f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Exception encountered when calling layer \"model_2\" (type Functional).\n    \n    Input 0 of layer \"dense\" is incompatible with the layer: expected axis -1of input shape to have value 512, but received input with shape (None, 2, 256)\n    \n    Call arguments received:\n      • inputs=('tf.Tensor(shape=(None, 1, 105), dtype=float32)', 'tf.Tensor(shape=(None, 256), dtype=float32)', 'tf.Tensor(shape=(None, 256), dtype=float32)', 'tf.Tensor(shape=(None, 256), dtype=float32)', 'tf.Tensor(shape=(None, 256), dtype=float32)')\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "for seq_index in [0, 1, 2, 3]:\n",
    "    input_seq = encoder_input[seq_index : seq_index+1]\n",
    "    decoded_sentence = predict_decode(input_seq)\n",
    "    \n",
    "    print(\"입력 : \", lines.src[seq_index])\n",
    "    print(\"정답 : \", lines.tar[seq_index][1:len(lines.tar[seq_index])-1])\n",
    "    print(\"번역 : \", decoded_sentence[:len(decoded_sentence)-1], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3caf13703c5b1c02abff9fa597e671e1239d1d668b6a345ae62ddadff9d8fc63"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('py37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
