{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "import prepare_data as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "      - train, test 데이터 가공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random_Crop = 30\n",
    "Patch_size = 32\n",
    "label_size = 20\n",
    "conv_side = 6\n",
    "scale = 2 \n",
    "\n",
    "def prepare_data(_path):\n",
    "    names = os.listdir(_path)\n",
    "    names = sorted(names)\n",
    "    nums = names.__len__()\n",
    "\n",
    "    data = np.zeros((nums * Random_Crop, 1, Patch_size, Patch_size), dtype=np.double)     # data = zeros(14*30, 1, 32, 32)   이미지 단일화\n",
    "    label = np.zeros((nums * Random_Crop, 1, label_size, label_size), dtype=np.double)    # label = zeros(14*30, 1, 20, 20)  이미지 단일화\n",
    "\n",
    "    for i in range(nums):\n",
    "        name = _path + names[i]\n",
    "        hr_img = cv2.imread(name, cv2.IMREAD_COLOR)\n",
    "        shape = hr_img.shape\n",
    "\n",
    "        hr_img = cv2.cvtColor(hr_img, cv2.COLOR_BGR2YCrCb)\n",
    "        hr_img = hr_img[:, :, 0]\n",
    "        \n",
    "        # 저화질 이미지 생성 (행렬로만 이루어져 있음)\n",
    "        # lr_img = cv2.resize(hr_img, (shape[1] / scale, shape[0] / scale))           # shape (h, w)\n",
    "        # lr_img = cv2.resize(lr_img, (shape[1], shape[0]))\n",
    "        \n",
    "        w, h, c = shape\n",
    "        new_height = int(h / scale)\n",
    "        new_width = int(w / scale)\n",
    "        lr_img = cv2.resize(hr_img, (new_height, new_width))           # shape (h, w)\n",
    "        lr_img = cv2.resize(lr_img, (shape[1], shape[0]))\n",
    "\n",
    "        # produce Random_Crop random coordinate to crop training img\n",
    "        Points_x = np.random.randint(0, min(shape[0], shape[1]) - Patch_size, Random_Crop)        # points_x = random(0, 낮은 값 - 32, 30)\n",
    "        Points_y = np.random.randint(0, min(shape[0], shape[1]) - Patch_size, Random_Crop)        # points_y = random(0, 낮은 값 - 32, 30)\n",
    "        \n",
    "        # 이미지 단일화\n",
    "        for j in range(Random_Crop):\n",
    "            lr_patch = lr_img[Points_x[j]: Points_x[j] + Patch_size, Points_y[j]: Points_y[j] + Patch_size]            # lr_patch = (n번째 + 32, n번째 + 32)\n",
    "            hr_patch = hr_img[Points_x[j]: Points_x[j] + Patch_size, Points_y[j]: Points_y[j] + Patch_size]\n",
    "\n",
    "            lr_patch = lr_patch.astype(float) / 255.\n",
    "            hr_patch = hr_patch.astype(float) / 255.\n",
    "\n",
    "            data[i * Random_Crop + j, 0, :, :] = lr_patch\n",
    "            label[i * Random_Crop + j, 0, :, :] = hr_patch[conv_side: -conv_side, conv_side: -conv_side]\n",
    "            # cv2.imshow(\"lr\", lr_patch)\n",
    "            # cv2.imshow(\"hr\", hr_patch)\n",
    "            # cv2.waitKey(0)\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 1, 20, 20) (2400, 1, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "# train 데이터\n",
    "train_y, train_x = prepare_data('./train/')\n",
    "print(train_x.shape, train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 1, 20, 20) (600, 1, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "# test 데이터\n",
    "test_y, test_x = prepare_data('./test/')\n",
    "print(test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h5파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_hdf5(data, labels, output_filename):\n",
    "    \"\"\"\n",
    "    This function is used to save image data and its label(s) to hdf5 file.\n",
    "    output_file.h5,contain data and label\n",
    "    \"\"\"\n",
    "\n",
    "    x = data.astype(np.float32)\n",
    "    y = labels.astype(np.float32)\n",
    "\n",
    "    with h5py.File(output_filename, 'w') as h:\n",
    "        h.create_dataset('data', data=x, shape=x.shape)\n",
    "        h.create_dataset('label', data=y, shape=y.shape)\n",
    "        # h.create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test 데이터 저장\n",
    "write_hdf5(train_x, train_y, 'train.h5')\n",
    "write_hdf5(test_x, test_y, 'test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label = pd.read_training_data(\"training.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25e87ba88e0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define model type\n",
    "SRCNN = Sequential()\n",
    "    \n",
    " # add model layers\n",
    "SRCNN.add(Conv2D(filters=128, kernel_size=(9, 9), kernel_initializer='glorot_uniform',\n",
    "                     activation='relu', padding='valid', use_bias=True, input_shape=(None, None, 1)))\n",
    "SRCNN.add(Conv2D(filters=64, kernel_size=(3, 3), kernel_initializer='glorot_uniform',\n",
    "                     activation='relu', padding='same', use_bias=True))\n",
    "SRCNN.add(Conv2D(filters=1, kernel_size=(5,5), kernel_initializer='glorot_uniform',\n",
    "                     activation='linear', padding='valid', use_bias=True))\n",
    "    \n",
    "# compile model\n",
    "SRCNN.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "SRCNN.fit(data, label, batch_size=128, shuffle=True, epochs=200, verbose=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
