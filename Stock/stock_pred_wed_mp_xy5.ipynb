{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>일자</th>\n",
       "      <th>시가</th>\n",
       "      <th>고가</th>\n",
       "      <th>저가</th>\n",
       "      <th>종가</th>\n",
       "      <th>전일비</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>등락률</th>\n",
       "      <th>거래량</th>\n",
       "      <th>금액(백만)</th>\n",
       "      <th>신용비</th>\n",
       "      <th>개인</th>\n",
       "      <th>기관</th>\n",
       "      <th>외인(수량)</th>\n",
       "      <th>외국계</th>\n",
       "      <th>프로그램</th>\n",
       "      <th>외인비</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021/12/17</td>\n",
       "      <td>76800</td>\n",
       "      <td>78000</td>\n",
       "      <td>76800</td>\n",
       "      <td>78000</td>\n",
       "      <td>▲</td>\n",
       "      <td>200</td>\n",
       "      <td>0.26</td>\n",
       "      <td>11802494.0</td>\n",
       "      <td>914987.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-733323</td>\n",
       "      <td>-907696</td>\n",
       "      <td>0</td>\n",
       "      <td>-257019</td>\n",
       "      <td>757837</td>\n",
       "      <td>51.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021/12/16</td>\n",
       "      <td>78500</td>\n",
       "      <td>78500</td>\n",
       "      <td>77400</td>\n",
       "      <td>77800</td>\n",
       "      <td>▲</td>\n",
       "      <td>200</td>\n",
       "      <td>0.26</td>\n",
       "      <td>11996128.0</td>\n",
       "      <td>934244.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-442445</td>\n",
       "      <td>-261746</td>\n",
       "      <td>-105777</td>\n",
       "      <td>571543</td>\n",
       "      <td>822030</td>\n",
       "      <td>51.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021/12/15</td>\n",
       "      <td>76400</td>\n",
       "      <td>77600</td>\n",
       "      <td>76300</td>\n",
       "      <td>77600</td>\n",
       "      <td>▲</td>\n",
       "      <td>600</td>\n",
       "      <td>0.78</td>\n",
       "      <td>9584939.0</td>\n",
       "      <td>738592.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-1118059</td>\n",
       "      <td>-654764</td>\n",
       "      <td>1095947</td>\n",
       "      <td>1946258</td>\n",
       "      <td>1706254</td>\n",
       "      <td>51.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021/12/14</td>\n",
       "      <td>76500</td>\n",
       "      <td>77200</td>\n",
       "      <td>76200</td>\n",
       "      <td>77000</td>\n",
       "      <td>▲</td>\n",
       "      <td>200</td>\n",
       "      <td>0.26</td>\n",
       "      <td>10976660.0</td>\n",
       "      <td>841447.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>198293</td>\n",
       "      <td>-1487295</td>\n",
       "      <td>1005909</td>\n",
       "      <td>804186</td>\n",
       "      <td>-132070</td>\n",
       "      <td>51.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021/12/13</td>\n",
       "      <td>77200</td>\n",
       "      <td>78300</td>\n",
       "      <td>76500</td>\n",
       "      <td>76800</td>\n",
       "      <td>▼</td>\n",
       "      <td>-100</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>15038750.0</td>\n",
       "      <td>1163285.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-181359</td>\n",
       "      <td>184966</td>\n",
       "      <td>-151301</td>\n",
       "      <td>-1388477</td>\n",
       "      <td>-606534</td>\n",
       "      <td>51.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021/12/10</td>\n",
       "      <td>77400</td>\n",
       "      <td>77600</td>\n",
       "      <td>76800</td>\n",
       "      <td>76900</td>\n",
       "      <td>▼</td>\n",
       "      <td>-1300</td>\n",
       "      <td>-1.66</td>\n",
       "      <td>9155219.0</td>\n",
       "      <td>705966.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1797829</td>\n",
       "      <td>-1071153</td>\n",
       "      <td>-728679</td>\n",
       "      <td>-505955</td>\n",
       "      <td>-1714088</td>\n",
       "      <td>51.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021/12/09</td>\n",
       "      <td>77400</td>\n",
       "      <td>78200</td>\n",
       "      <td>77000</td>\n",
       "      <td>78200</td>\n",
       "      <td>▲</td>\n",
       "      <td>800</td>\n",
       "      <td>1.03</td>\n",
       "      <td>21604528.0</td>\n",
       "      <td>1681184.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-1671678</td>\n",
       "      <td>-491078</td>\n",
       "      <td>2768853</td>\n",
       "      <td>2796574</td>\n",
       "      <td>3486578</td>\n",
       "      <td>51.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021/12/08</td>\n",
       "      <td>78300</td>\n",
       "      <td>78600</td>\n",
       "      <td>77100</td>\n",
       "      <td>77400</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21558340.0</td>\n",
       "      <td>1662979.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-2524520</td>\n",
       "      <td>2586682</td>\n",
       "      <td>703379</td>\n",
       "      <td>-941476</td>\n",
       "      <td>48232</td>\n",
       "      <td>51.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021/12/07</td>\n",
       "      <td>76100</td>\n",
       "      <td>77700</td>\n",
       "      <td>75600</td>\n",
       "      <td>77400</td>\n",
       "      <td>▲</td>\n",
       "      <td>1100</td>\n",
       "      <td>1.44</td>\n",
       "      <td>19232453.0</td>\n",
       "      <td>1477888.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-2997907</td>\n",
       "      <td>-547244</td>\n",
       "      <td>4216958</td>\n",
       "      <td>3518986</td>\n",
       "      <td>123462</td>\n",
       "      <td>51.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021/12/06</td>\n",
       "      <td>75100</td>\n",
       "      <td>76700</td>\n",
       "      <td>74900</td>\n",
       "      <td>76300</td>\n",
       "      <td>▲</td>\n",
       "      <td>700</td>\n",
       "      <td>0.93</td>\n",
       "      <td>16391250.0</td>\n",
       "      <td>1245309.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-3062604</td>\n",
       "      <td>576498</td>\n",
       "      <td>2508191</td>\n",
       "      <td>2146417</td>\n",
       "      <td>2070776</td>\n",
       "      <td>51.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021/12/03</td>\n",
       "      <td>75600</td>\n",
       "      <td>76000</td>\n",
       "      <td>74100</td>\n",
       "      <td>75600</td>\n",
       "      <td>▼</td>\n",
       "      <td>-200</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>18330240.0</td>\n",
       "      <td>1375861.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>133267</td>\n",
       "      <td>-157689</td>\n",
       "      <td>-630400</td>\n",
       "      <td>467310</td>\n",
       "      <td>-532651</td>\n",
       "      <td>51.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2021/12/02</td>\n",
       "      <td>73900</td>\n",
       "      <td>75800</td>\n",
       "      <td>73800</td>\n",
       "      <td>75800</td>\n",
       "      <td>▲</td>\n",
       "      <td>1400</td>\n",
       "      <td>1.88</td>\n",
       "      <td>23652940.0</td>\n",
       "      <td>1778785.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-6603764</td>\n",
       "      <td>-164462</td>\n",
       "      <td>6327924</td>\n",
       "      <td>5789997</td>\n",
       "      <td>5214948</td>\n",
       "      <td>51.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2021/12/01</td>\n",
       "      <td>72000</td>\n",
       "      <td>74800</td>\n",
       "      <td>71600</td>\n",
       "      <td>74400</td>\n",
       "      <td>▲</td>\n",
       "      <td>3100</td>\n",
       "      <td>4.35</td>\n",
       "      <td>21954856.0</td>\n",
       "      <td>1610885.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-6250521</td>\n",
       "      <td>415580</td>\n",
       "      <td>5498391</td>\n",
       "      <td>5601567</td>\n",
       "      <td>3706678</td>\n",
       "      <td>51.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2021/11/30</td>\n",
       "      <td>73200</td>\n",
       "      <td>73900</td>\n",
       "      <td>70500</td>\n",
       "      <td>71300</td>\n",
       "      <td>▼</td>\n",
       "      <td>-1000</td>\n",
       "      <td>-1.38</td>\n",
       "      <td>30364841.0</td>\n",
       "      <td>2183678.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1834720</td>\n",
       "      <td>-2841806</td>\n",
       "      <td>1600552</td>\n",
       "      <td>370200</td>\n",
       "      <td>939616</td>\n",
       "      <td>51.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2021/11/29</td>\n",
       "      <td>71700</td>\n",
       "      <td>73000</td>\n",
       "      <td>71400</td>\n",
       "      <td>72300</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16682559.0</td>\n",
       "      <td>1206606.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-2395401</td>\n",
       "      <td>3021851</td>\n",
       "      <td>-494165</td>\n",
       "      <td>-566353</td>\n",
       "      <td>-525529</td>\n",
       "      <td>51.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2021/11/26</td>\n",
       "      <td>73500</td>\n",
       "      <td>74100</td>\n",
       "      <td>72000</td>\n",
       "      <td>72300</td>\n",
       "      <td>▼</td>\n",
       "      <td>-1400</td>\n",
       "      <td>-1.90</td>\n",
       "      <td>13002242.0</td>\n",
       "      <td>944378.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1825155</td>\n",
       "      <td>-1070320</td>\n",
       "      <td>-1157622</td>\n",
       "      <td>-560900</td>\n",
       "      <td>-1313864</td>\n",
       "      <td>51.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2021/11/25</td>\n",
       "      <td>75100</td>\n",
       "      <td>75100</td>\n",
       "      <td>73600</td>\n",
       "      <td>73700</td>\n",
       "      <td>▼</td>\n",
       "      <td>-1100</td>\n",
       "      <td>-1.47</td>\n",
       "      <td>12559258.0</td>\n",
       "      <td>929571.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>694786</td>\n",
       "      <td>-179371</td>\n",
       "      <td>-353300</td>\n",
       "      <td>-143417</td>\n",
       "      <td>-704752</td>\n",
       "      <td>51.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2021/11/24</td>\n",
       "      <td>76000</td>\n",
       "      <td>76200</td>\n",
       "      <td>74100</td>\n",
       "      <td>74800</td>\n",
       "      <td>▼</td>\n",
       "      <td>-500</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>15652305.0</td>\n",
       "      <td>1174196.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>701745</td>\n",
       "      <td>-2258726</td>\n",
       "      <td>1484318</td>\n",
       "      <td>1421283</td>\n",
       "      <td>-596182</td>\n",
       "      <td>51.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2021/11/23</td>\n",
       "      <td>76000</td>\n",
       "      <td>76000</td>\n",
       "      <td>74500</td>\n",
       "      <td>75300</td>\n",
       "      <td>▲</td>\n",
       "      <td>400</td>\n",
       "      <td>0.53</td>\n",
       "      <td>22029195.0</td>\n",
       "      <td>1656722.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-2177512</td>\n",
       "      <td>-2811514</td>\n",
       "      <td>4884832</td>\n",
       "      <td>5578065</td>\n",
       "      <td>1247451</td>\n",
       "      <td>51.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2021/11/22</td>\n",
       "      <td>73300</td>\n",
       "      <td>75200</td>\n",
       "      <td>73000</td>\n",
       "      <td>74900</td>\n",
       "      <td>▲</td>\n",
       "      <td>3700</td>\n",
       "      <td>5.20</td>\n",
       "      <td>27506623.0</td>\n",
       "      <td>2047228.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-8689803</td>\n",
       "      <td>3034399</td>\n",
       "      <td>5716921</td>\n",
       "      <td>4760374</td>\n",
       "      <td>3500256</td>\n",
       "      <td>51.31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            일자     시가     고가     저가     종가 전일비  Unnamed: 6   등락률         거래량  \\\n",
       "0   2021/12/17  76800  78000  76800  78000   ▲         200  0.26  11802494.0   \n",
       "1   2021/12/16  78500  78500  77400  77800   ▲         200  0.26  11996128.0   \n",
       "2   2021/12/15  76400  77600  76300  77600   ▲         600  0.78   9584939.0   \n",
       "3   2021/12/14  76500  77200  76200  77000   ▲         200  0.26  10976660.0   \n",
       "4   2021/12/13  77200  78300  76500  76800   ▼        -100 -0.13  15038750.0   \n",
       "5   2021/12/10  77400  77600  76800  76900   ▼       -1300 -1.66   9155219.0   \n",
       "6   2021/12/09  77400  78200  77000  78200   ▲         800  1.03  21604528.0   \n",
       "7   2021/12/08  78300  78600  77100  77400               0  0.00  21558340.0   \n",
       "8   2021/12/07  76100  77700  75600  77400   ▲        1100  1.44  19232453.0   \n",
       "9   2021/12/06  75100  76700  74900  76300   ▲         700  0.93  16391250.0   \n",
       "10  2021/12/03  75600  76000  74100  75600   ▼        -200 -0.26  18330240.0   \n",
       "11  2021/12/02  73900  75800  73800  75800   ▲        1400  1.88  23652940.0   \n",
       "12  2021/12/01  72000  74800  71600  74400   ▲        3100  4.35  21954856.0   \n",
       "13  2021/11/30  73200  73900  70500  71300   ▼       -1000 -1.38  30364841.0   \n",
       "14  2021/11/29  71700  73000  71400  72300               0  0.00  16682559.0   \n",
       "15  2021/11/26  73500  74100  72000  72300   ▼       -1400 -1.90  13002242.0   \n",
       "16  2021/11/25  75100  75100  73600  73700   ▼       -1100 -1.47  12559258.0   \n",
       "17  2021/11/24  76000  76200  74100  74800   ▼        -500 -0.66  15652305.0   \n",
       "18  2021/11/23  76000  76000  74500  75300   ▲         400  0.53  22029195.0   \n",
       "19  2021/11/22  73300  75200  73000  74900   ▲        3700  5.20  27506623.0   \n",
       "\n",
       "       금액(백만)   신용비       개인       기관   외인(수량)      외국계     프로그램    외인비  \n",
       "0    914987.0  0.00  -733323  -907696        0  -257019   757837  51.78  \n",
       "1    934244.0  0.13  -442445  -261746  -105777   571543   822030  51.78  \n",
       "2    738592.0  0.14 -1118059  -654764  1095947  1946258  1706254  51.79  \n",
       "3    841447.0  0.14   198293 -1487295  1005909   804186  -132070  51.77  \n",
       "4   1163285.0  0.13  -181359   184966  -151301 -1388477  -606534  51.75  \n",
       "5    705966.0  0.13  1797829 -1071153  -728679  -505955 -1714088  51.75  \n",
       "6   1681184.0  0.14 -1671678  -491078  2768853  2796574  3486578  51.77  \n",
       "7   1662979.0  0.14 -2524520  2586682   703379  -941476    48232  51.72  \n",
       "8   1477888.0  0.14 -2997907  -547244  4216958  3518986   123462  51.71  \n",
       "9   1245309.0  0.14 -3062604   576498  2508191  2146417  2070776  51.64  \n",
       "10  1375861.0  0.15   133267  -157689  -630400   467310  -532651  51.60  \n",
       "11  1778785.0  0.15 -6603764  -164462  6327924  5789997  5214948  51.61  \n",
       "12  1610885.0  0.15 -6250521   415580  5498391  5601567  3706678  51.50  \n",
       "13  2183678.0  0.15  1834720 -2841806  1600552   370200   939616  51.41  \n",
       "14  1206606.0  0.15 -2395401  3021851  -494165  -566353  -525529  51.38  \n",
       "15   944378.0  0.15  1825155 -1070320 -1157622  -560900 -1313864  51.39  \n",
       "16   929571.0  0.15   694786  -179371  -353300  -143417  -704752  51.41  \n",
       "17  1174196.0  0.15   701745 -2258726  1484318  1421283  -596182  51.41  \n",
       "18  1656722.0  0.16 -2177512 -2811514  4884832  5578065  1247451  51.39  \n",
       "19  2047228.0  0.16 -8689803  3034399  5716921  4760374  3500256  51.31  "
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ss = pd.read_csv(\"D:/_data/stock predict/삼성전자.csv\", thousands=',', encoding='CP949')\n",
    "ss = ss.drop(range(20, 1120), axis=0)\n",
    "ki = pd.read_csv(\"D:/_data/stock predict/키움증권.csv\", thousands=',', encoding='CP949')\n",
    "ki = ki.drop(range(20, 1060), axis=0)\n",
    "\n",
    "ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, Dropout\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>일자</th>\n",
       "      <th>시가</th>\n",
       "      <th>고가</th>\n",
       "      <th>저가</th>\n",
       "      <th>종가</th>\n",
       "      <th>전일비</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>등락률</th>\n",
       "      <th>거래량</th>\n",
       "      <th>금액(백만)</th>\n",
       "      <th>신용비</th>\n",
       "      <th>개인</th>\n",
       "      <th>기관</th>\n",
       "      <th>외인(수량)</th>\n",
       "      <th>외국계</th>\n",
       "      <th>프로그램</th>\n",
       "      <th>외인비</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021/11/22</td>\n",
       "      <td>106000</td>\n",
       "      <td>109000</td>\n",
       "      <td>105000</td>\n",
       "      <td>109000</td>\n",
       "      <td>▲</td>\n",
       "      <td>3500</td>\n",
       "      <td>3.32</td>\n",
       "      <td>89564</td>\n",
       "      <td>9563</td>\n",
       "      <td>0.93</td>\n",
       "      <td>-13426</td>\n",
       "      <td>-10878</td>\n",
       "      <td>24865</td>\n",
       "      <td>23544</td>\n",
       "      <td>24075</td>\n",
       "      <td>25.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021/11/23</td>\n",
       "      <td>107500</td>\n",
       "      <td>107500</td>\n",
       "      <td>105500</td>\n",
       "      <td>107500</td>\n",
       "      <td>▼</td>\n",
       "      <td>-1500</td>\n",
       "      <td>-1.38</td>\n",
       "      <td>57672</td>\n",
       "      <td>6143</td>\n",
       "      <td>0.94</td>\n",
       "      <td>11818</td>\n",
       "      <td>-13417</td>\n",
       "      <td>-1065</td>\n",
       "      <td>1528</td>\n",
       "      <td>-8687</td>\n",
       "      <td>25.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021/11/24</td>\n",
       "      <td>107000</td>\n",
       "      <td>107000</td>\n",
       "      <td>105000</td>\n",
       "      <td>105000</td>\n",
       "      <td>▼</td>\n",
       "      <td>-2500</td>\n",
       "      <td>-2.33</td>\n",
       "      <td>62724</td>\n",
       "      <td>6620</td>\n",
       "      <td>0.93</td>\n",
       "      <td>26965</td>\n",
       "      <td>-8031</td>\n",
       "      <td>-26006</td>\n",
       "      <td>-17199</td>\n",
       "      <td>-20042</td>\n",
       "      <td>25.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021/11/25</td>\n",
       "      <td>105000</td>\n",
       "      <td>106500</td>\n",
       "      <td>104000</td>\n",
       "      <td>105500</td>\n",
       "      <td>▲</td>\n",
       "      <td>500</td>\n",
       "      <td>0.48</td>\n",
       "      <td>38215</td>\n",
       "      <td>4026</td>\n",
       "      <td>0.94</td>\n",
       "      <td>-7183</td>\n",
       "      <td>3216</td>\n",
       "      <td>10319</td>\n",
       "      <td>1666</td>\n",
       "      <td>-3350</td>\n",
       "      <td>25.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021/11/26</td>\n",
       "      <td>104500</td>\n",
       "      <td>106000</td>\n",
       "      <td>102000</td>\n",
       "      <td>103000</td>\n",
       "      <td>▼</td>\n",
       "      <td>-2500</td>\n",
       "      <td>-2.37</td>\n",
       "      <td>77033</td>\n",
       "      <td>7991</td>\n",
       "      <td>0.96</td>\n",
       "      <td>14505</td>\n",
       "      <td>5517</td>\n",
       "      <td>-26186</td>\n",
       "      <td>-15546</td>\n",
       "      <td>-25613</td>\n",
       "      <td>25.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021/11/29</td>\n",
       "      <td>100000</td>\n",
       "      <td>104000</td>\n",
       "      <td>100000</td>\n",
       "      <td>102500</td>\n",
       "      <td>▼</td>\n",
       "      <td>-500</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>78470</td>\n",
       "      <td>8007</td>\n",
       "      <td>0.95</td>\n",
       "      <td>-21785</td>\n",
       "      <td>9951</td>\n",
       "      <td>10834</td>\n",
       "      <td>1718</td>\n",
       "      <td>-192</td>\n",
       "      <td>25.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021/11/30</td>\n",
       "      <td>102500</td>\n",
       "      <td>103000</td>\n",
       "      <td>96000</td>\n",
       "      <td>97500</td>\n",
       "      <td>▼</td>\n",
       "      <td>-5000</td>\n",
       "      <td>-4.88</td>\n",
       "      <td>169524</td>\n",
       "      <td>16764</td>\n",
       "      <td>0.93</td>\n",
       "      <td>62687</td>\n",
       "      <td>-27749</td>\n",
       "      <td>-59027</td>\n",
       "      <td>-43107</td>\n",
       "      <td>-47586</td>\n",
       "      <td>25.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021/12/01</td>\n",
       "      <td>97000</td>\n",
       "      <td>99800</td>\n",
       "      <td>96600</td>\n",
       "      <td>99600</td>\n",
       "      <td>▲</td>\n",
       "      <td>2100</td>\n",
       "      <td>2.15</td>\n",
       "      <td>79903</td>\n",
       "      <td>7875</td>\n",
       "      <td>0.91</td>\n",
       "      <td>-18847</td>\n",
       "      <td>4984</td>\n",
       "      <td>8628</td>\n",
       "      <td>8973</td>\n",
       "      <td>9911</td>\n",
       "      <td>25.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021/12/02</td>\n",
       "      <td>98100</td>\n",
       "      <td>104000</td>\n",
       "      <td>98100</td>\n",
       "      <td>103500</td>\n",
       "      <td>▲</td>\n",
       "      <td>3900</td>\n",
       "      <td>3.92</td>\n",
       "      <td>75890</td>\n",
       "      <td>7705</td>\n",
       "      <td>0.94</td>\n",
       "      <td>-38201</td>\n",
       "      <td>11298</td>\n",
       "      <td>13384</td>\n",
       "      <td>10192</td>\n",
       "      <td>26511</td>\n",
       "      <td>25.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021/12/03</td>\n",
       "      <td>102500</td>\n",
       "      <td>106000</td>\n",
       "      <td>102000</td>\n",
       "      <td>105500</td>\n",
       "      <td>▲</td>\n",
       "      <td>2000</td>\n",
       "      <td>1.93</td>\n",
       "      <td>65729</td>\n",
       "      <td>6890</td>\n",
       "      <td>0.92</td>\n",
       "      <td>-21284</td>\n",
       "      <td>13087</td>\n",
       "      <td>7616</td>\n",
       "      <td>669</td>\n",
       "      <td>3073</td>\n",
       "      <td>25.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021/12/06</td>\n",
       "      <td>105500</td>\n",
       "      <td>108500</td>\n",
       "      <td>104000</td>\n",
       "      <td>107500</td>\n",
       "      <td>▲</td>\n",
       "      <td>2000</td>\n",
       "      <td>1.90</td>\n",
       "      <td>77250</td>\n",
       "      <td>8276</td>\n",
       "      <td>0.89</td>\n",
       "      <td>-40876</td>\n",
       "      <td>5377</td>\n",
       "      <td>36004</td>\n",
       "      <td>26747</td>\n",
       "      <td>17436</td>\n",
       "      <td>25.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2021/12/07</td>\n",
       "      <td>107500</td>\n",
       "      <td>108500</td>\n",
       "      <td>106500</td>\n",
       "      <td>108000</td>\n",
       "      <td>▲</td>\n",
       "      <td>500</td>\n",
       "      <td>0.47</td>\n",
       "      <td>46518</td>\n",
       "      <td>5008</td>\n",
       "      <td>0.87</td>\n",
       "      <td>10363</td>\n",
       "      <td>296</td>\n",
       "      <td>-26729</td>\n",
       "      <td>-5199</td>\n",
       "      <td>-10394</td>\n",
       "      <td>25.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2021/12/08</td>\n",
       "      <td>108000</td>\n",
       "      <td>109500</td>\n",
       "      <td>107500</td>\n",
       "      <td>107500</td>\n",
       "      <td>▼</td>\n",
       "      <td>-500</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>49085</td>\n",
       "      <td>5329</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-7038</td>\n",
       "      <td>5396</td>\n",
       "      <td>-4363</td>\n",
       "      <td>1143</td>\n",
       "      <td>-591</td>\n",
       "      <td>25.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2021/12/09</td>\n",
       "      <td>108500</td>\n",
       "      <td>109000</td>\n",
       "      <td>106500</td>\n",
       "      <td>108000</td>\n",
       "      <td>▲</td>\n",
       "      <td>500</td>\n",
       "      <td>0.47</td>\n",
       "      <td>62923</td>\n",
       "      <td>6788</td>\n",
       "      <td>0.86</td>\n",
       "      <td>-3385</td>\n",
       "      <td>7495</td>\n",
       "      <td>6090</td>\n",
       "      <td>970</td>\n",
       "      <td>1767</td>\n",
       "      <td>25.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2021/12/10</td>\n",
       "      <td>108000</td>\n",
       "      <td>108500</td>\n",
       "      <td>106500</td>\n",
       "      <td>106500</td>\n",
       "      <td>▼</td>\n",
       "      <td>-1500</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>28979</td>\n",
       "      <td>3105</td>\n",
       "      <td>0.85</td>\n",
       "      <td>2080</td>\n",
       "      <td>-6921</td>\n",
       "      <td>8941</td>\n",
       "      <td>-798</td>\n",
       "      <td>-1877</td>\n",
       "      <td>25.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2021/12/13</td>\n",
       "      <td>107000</td>\n",
       "      <td>109500</td>\n",
       "      <td>107000</td>\n",
       "      <td>107500</td>\n",
       "      <td>▲</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.94</td>\n",
       "      <td>52503</td>\n",
       "      <td>5695</td>\n",
       "      <td>0.83</td>\n",
       "      <td>-13963</td>\n",
       "      <td>7746</td>\n",
       "      <td>7576</td>\n",
       "      <td>695</td>\n",
       "      <td>8305</td>\n",
       "      <td>25.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2021/12/14</td>\n",
       "      <td>106500</td>\n",
       "      <td>109000</td>\n",
       "      <td>106500</td>\n",
       "      <td>107000</td>\n",
       "      <td>▼</td>\n",
       "      <td>-500</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>64977</td>\n",
       "      <td>6974</td>\n",
       "      <td>0.83</td>\n",
       "      <td>4777</td>\n",
       "      <td>-20135</td>\n",
       "      <td>15033</td>\n",
       "      <td>-1107</td>\n",
       "      <td>2477</td>\n",
       "      <td>25.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2021/12/15</td>\n",
       "      <td>107000</td>\n",
       "      <td>108000</td>\n",
       "      <td>106500</td>\n",
       "      <td>107500</td>\n",
       "      <td>▲</td>\n",
       "      <td>500</td>\n",
       "      <td>0.47</td>\n",
       "      <td>23210</td>\n",
       "      <td>2496</td>\n",
       "      <td>0.81</td>\n",
       "      <td>-4089</td>\n",
       "      <td>1368</td>\n",
       "      <td>-915</td>\n",
       "      <td>5065</td>\n",
       "      <td>-1671</td>\n",
       "      <td>25.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2021/12/16</td>\n",
       "      <td>109500</td>\n",
       "      <td>109500</td>\n",
       "      <td>107000</td>\n",
       "      <td>107500</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>45031</td>\n",
       "      <td>4858</td>\n",
       "      <td>0.82</td>\n",
       "      <td>956</td>\n",
       "      <td>13405</td>\n",
       "      <td>-23661</td>\n",
       "      <td>-10182</td>\n",
       "      <td>-12948</td>\n",
       "      <td>25.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2021/12/17</td>\n",
       "      <td>107000</td>\n",
       "      <td>109500</td>\n",
       "      <td>106500</td>\n",
       "      <td>109500</td>\n",
       "      <td>▲</td>\n",
       "      <td>2000</td>\n",
       "      <td>1.86</td>\n",
       "      <td>60487</td>\n",
       "      <td>6576</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-16202</td>\n",
       "      <td>6443</td>\n",
       "      <td>0</td>\n",
       "      <td>7348</td>\n",
       "      <td>8805</td>\n",
       "      <td>25.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            일자      시가      고가      저가      종가 전일비  Unnamed: 6   등락률     거래량  \\\n",
       "0   2021/11/22  106000  109000  105000  109000   ▲        3500  3.32   89564   \n",
       "1   2021/11/23  107500  107500  105500  107500   ▼       -1500 -1.38   57672   \n",
       "2   2021/11/24  107000  107000  105000  105000   ▼       -2500 -2.33   62724   \n",
       "3   2021/11/25  105000  106500  104000  105500   ▲         500  0.48   38215   \n",
       "4   2021/11/26  104500  106000  102000  103000   ▼       -2500 -2.37   77033   \n",
       "5   2021/11/29  100000  104000  100000  102500   ▼        -500 -0.49   78470   \n",
       "6   2021/11/30  102500  103000   96000   97500   ▼       -5000 -4.88  169524   \n",
       "7   2021/12/01   97000   99800   96600   99600   ▲        2100  2.15   79903   \n",
       "8   2021/12/02   98100  104000   98100  103500   ▲        3900  3.92   75890   \n",
       "9   2021/12/03  102500  106000  102000  105500   ▲        2000  1.93   65729   \n",
       "10  2021/12/06  105500  108500  104000  107500   ▲        2000  1.90   77250   \n",
       "11  2021/12/07  107500  108500  106500  108000   ▲         500  0.47   46518   \n",
       "12  2021/12/08  108000  109500  107500  107500   ▼        -500 -0.46   49085   \n",
       "13  2021/12/09  108500  109000  106500  108000   ▲         500  0.47   62923   \n",
       "14  2021/12/10  108000  108500  106500  106500   ▼       -1500 -1.39   28979   \n",
       "15  2021/12/13  107000  109500  107000  107500   ▲        1000  0.94   52503   \n",
       "16  2021/12/14  106500  109000  106500  107000   ▼        -500 -0.47   64977   \n",
       "17  2021/12/15  107000  108000  106500  107500   ▲         500  0.47   23210   \n",
       "18  2021/12/16  109500  109500  107000  107500               0  0.00   45031   \n",
       "19  2021/12/17  107000  109500  106500  109500   ▲        2000  1.86   60487   \n",
       "\n",
       "    금액(백만)   신용비     개인     기관  외인(수량)    외국계   프로그램    외인비  \n",
       "0     9563  0.93 -13426 -10878   24865  23544  24075  25.61  \n",
       "1     6143  0.94  11818 -13417   -1065   1528  -8687  25.61  \n",
       "2     6620  0.93  26965  -8031  -26006 -17199 -20042  25.51  \n",
       "3     4026  0.94  -7183   3216   10319   1666  -3350  25.55  \n",
       "4     7991  0.96  14505   5517  -26186 -15546 -25613  25.45  \n",
       "5     8007  0.95 -21785   9951   10834   1718   -192  25.49  \n",
       "6    16764  0.93  62687 -27749  -59027 -43107 -47586  25.27  \n",
       "7     7875  0.91 -18847   4984    8628   8973   9911  25.30  \n",
       "8     7705  0.94 -38201  11298   13384  10192  26511  25.35  \n",
       "9     6890  0.92 -21284  13087    7616    669   3073  25.38  \n",
       "10    8276  0.89 -40876   5377   36004  26747  17436  25.52  \n",
       "11    5008  0.87  10363    296  -26729  -5199 -10394  25.41  \n",
       "12    5329  0.85  -7038   5396   -4363   1143   -591  25.40  \n",
       "13    6788  0.86  -3385   7495    6090    970   1767  25.42  \n",
       "14    3105  0.85   2080  -6921    8941   -798  -1877  25.46  \n",
       "15    5695  0.83 -13963   7746    7576    695   8305  25.48  \n",
       "16    6974  0.83   4777 -20135   15033  -1107   2477  25.54  \n",
       "17    2496  0.81  -4089   1368    -915   5065  -1671  25.54  \n",
       "18    4858  0.82    956  13405  -23661 -10182 -12948  25.45  \n",
       "19    6576  0.00 -16202   6443       0   7348   8805  25.45  "
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인덱스 재배열\n",
    "ss = ss.loc[::-1].reset_index(drop=True)\n",
    "ki = ki.loc[::-1].reset_index(drop=True)\n",
    "\n",
    "ki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 2)"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 필요한 컬럼만 남겨두기\n",
    "x_ss = ss.drop(['일자', '시가', '고가', '저가', '종가', '전일비', 'Unnamed: 6', '등락률',\n",
    "                '신용비', '개인', '기관', '외인(수량)', '외국계', '프로그램', '외인비'], axis =1)\n",
    "x_ss = np.array(x_ss)\n",
    "x_ki = ki.drop(['일자', '시가', '고가', '저가', '종가', '전일비', 'Unnamed: 6', '등락률',\n",
    "                '신용비',  '개인', '기관', '외인(수량)', '외국계', '프로그램', '외인비'], axis =1)\n",
    "x_ki = np.array(x_ki)\n",
    "\n",
    "\n",
    "# '일자', '시가', '고가', '저가', '종가', '전일비', 'Unnamed: 6', '등락률', '거래량', '금액(백만)', '신용비', '개인', '기관', '외인(수량)', '외국계', '프로그램', '외인비'\n",
    "\n",
    "x_ss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17, 2, 1), (17, 3))"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split 함수 정의\n",
    "def split_xy(dataset, time_steps, y_column):\n",
    "    x, y = list(), list()\n",
    "    for i in range(len(dataset)):\n",
    "        x_end_number = i + time_steps\n",
    "        y_end_number = x_end_number + y_column-1\n",
    "        \n",
    "        if y_end_number > len(dataset):\n",
    "            break\n",
    "        tmp_x = dataset[i:x_end_number, 1:]\n",
    "        tmp_y = dataset[x_end_number-1:y_end_number, 0]\n",
    "        x.append(tmp_x)\n",
    "        y.append(tmp_y)\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "x_ssp, y_ssp = split_xy(x_ss, 2, 3)\n",
    "x_kip, y_kip = split_xy(x_ki, 2, 3)\n",
    "\n",
    "x_ssp.shape, y_ssp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 삼성 데이터 train_test_split 적용\n",
    "x1_train, x1_test, y1_train, y1_test = train_test_split(x_ssp, y_ssp, train_size=0.8, random_state=66)\n",
    "\n",
    "# 키움 데이터 train_test_split 적용\n",
    "x2_train, x2_test, y2_train, y2_test = train_test_split(x_kip, y_kip, train_size=0.8, random_state=66)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "#삼성 input\n",
    "input1 = Input(shape=(2, 1))\n",
    "dense1_1 = LSTM(32, activation='relu')(input1)\n",
    "dense1_2 = Dense(16, activation='relu')(dense1_1)\n",
    "output1 = Dense(4, activation='relu')(dense1_2)\n",
    "\n",
    "#키움 input\n",
    "input2 = Input(shape=(2, 1))\n",
    "dense2_1 = LSTM(32, activation='relu')(input2)\n",
    "dense2_2 = Dense(16, activation='relu')(dense2_1)\n",
    "output2 = Dense(4, activation='relu')(dense2_2)\n",
    "\n",
    "#앙상블\n",
    "from tensorflow.keras.layers import concatenate\n",
    "merge1 = concatenate([output1, output2])\n",
    "\n",
    "#삼성 out\n",
    "output1_1 = Dense(16, activation='relu')(merge1)\n",
    "output1_2 = Dense(8)(output1_1)\n",
    "ss_output = Dense(1)(output1_2)\n",
    "\n",
    "#키움 out\n",
    "output2_1 = Dense(16, activation='relu')(merge1)\n",
    "output2_2 = Dense(8)(output2_1)\n",
    "ku_output = Dense(1)(output2_2)\n",
    "\n",
    "model = Model(inputs=[input1, input2], outputs=[ss_output, ku_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_29\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_59 (InputLayer)           [(None, 2, 1)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_60 (InputLayer)           [(None, 2, 1)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_58 (LSTM)                  (None, 32)           4352        input_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_59 (LSTM)                  (None, 32)           4352        input_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_290 (Dense)               (None, 16)           528         lstm_58[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_292 (Dense)               (None, 16)           528         lstm_59[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_291 (Dense)               (None, 4)            68          dense_290[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_293 (Dense)               (None, 4)            68          dense_292[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 8)            0           dense_291[0][0]                  \n",
      "                                                                 dense_293[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_294 (Dense)               (None, 16)           144         concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_297 (Dense)               (None, 16)           144         concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_295 (Dense)               (None, 8)            136         dense_294[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_298 (Dense)               (None, 8)            136         dense_297[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_296 (Dense)               (None, 1)            9           dense_295[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_299 (Dense)               (None, 1)            9           dense_298[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 10,474\n",
      "Trainable params: 10,474\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "컴파일 & 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "9/9 [==============================] - 1s 32ms/step - loss: 17616344.0000 - dense_296_loss: 17565424.0000 - dense_299_loss: 50921.4766 - val_loss: 17225488.0000 - val_dense_296_loss: 17174490.0000 - val_dense_299_loss: 50998.4375\n",
      "Epoch 2/1000\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 17594822.0000 - dense_296_loss: 17543018.0000 - dense_299_loss: 51804.2031 - val_loss: 17205570.0000 - val_dense_296_loss: 17156180.0000 - val_dense_299_loss: 49390.0508\n",
      "Epoch 3/1000\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 17566776.0000 - dense_296_loss: 17522278.0000 - dense_299_loss: 44497.2031 - val_loss: 17172702.0000 - val_dense_296_loss: 17135572.0000 - val_dense_299_loss: 37129.8867\n",
      "Epoch 4/1000\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 17523302.0000 - dense_296_loss: 17492824.0000 - dense_299_loss: 30475.0488 - val_loss: 17121066.0000 - val_dense_296_loss: 17098640.0000 - val_dense_299_loss: 22424.8789\n",
      "Epoch 5/1000\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 17466392.0000 - dense_296_loss: 17444988.0000 - dense_299_loss: 21404.6270 - val_loss: 17060236.0000 - val_dense_296_loss: 17043344.0000 - val_dense_299_loss: 16893.4316\n",
      "Epoch 6/1000\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 17396930.0000 - dense_296_loss: 17374660.0000 - dense_299_loss: 22268.2441 - val_loss: 16981468.0000 - val_dense_296_loss: 16963962.0000 - val_dense_299_loss: 17507.5078\n",
      "Epoch 7/1000\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 17290932.0000 - dense_296_loss: 17269572.0000 - dense_299_loss: 21358.5879 - val_loss: 16857442.0000 - val_dense_296_loss: 16839494.0000 - val_dense_299_loss: 17946.9629\n",
      "Epoch 8/1000\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 17124336.0000 - dense_296_loss: 17103070.0000 - dense_299_loss: 21266.4277 - val_loss: 16663024.0000 - val_dense_296_loss: 16644375.0000 - val_dense_299_loss: 18650.6270\n",
      "Epoch 9/1000\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 16862102.0000 - dense_296_loss: 16839976.0000 - dense_299_loss: 22128.6113 - val_loss: 16351873.0000 - val_dense_296_loss: 16334522.0000 - val_dense_299_loss: 17352.1895\n",
      "Epoch 10/1000\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 16460514.0000 - dense_296_loss: 16438180.0000 - dense_299_loss: 22333.8477 - val_loss: 15862333.0000 - val_dense_296_loss: 15842764.0000 - val_dense_299_loss: 19568.5098\n",
      "Epoch 11/1000\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 15779547.0000 - dense_296_loss: 15757397.0000 - dense_299_loss: 22149.1426 - val_loss: 15107568.0000 - val_dense_296_loss: 15088225.0000 - val_dense_299_loss: 19344.3594\n",
      "Epoch 12/1000\n",
      "9/9 [==============================] - ETA: 0s - loss: 13796962.0000 - dense_296_loss: 13770796.0000 - dense_299_loss: 26166.267 - 0s 3ms/step - loss: 14803823.0000 - dense_296_loss: 14781270.0000 - dense_299_loss: 22554.8809 - val_loss: 14126223.0000 - val_dense_296_loss: 14105420.0000 - val_dense_299_loss: 20803.4824\n",
      "Epoch 13/1000\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 13169803.0000 - dense_296_loss: 13145140.0000 - dense_299_loss: 24662.6562 - val_loss: 12384712.0000 - val_dense_296_loss: 12357131.0000 - val_dense_299_loss: 27581.6152\n",
      "Epoch 14/1000\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 10781852.0000 - dense_296_loss: 10759499.0000 - dense_299_loss: 22352.8203 - val_loss: 9752839.0000 - val_dense_296_loss: 9731054.0000 - val_dense_299_loss: 21785.8066\n",
      "Epoch 15/1000\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 7333084.0000 - dense_296_loss: 7310519.0000 - dense_299_loss: 22564.9590 - val_loss: 5870573.0000 - val_dense_296_loss: 5848467.0000 - val_dense_299_loss: 22106.9922\n",
      "Epoch 16/1000\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 4536114.0000 - dense_296_loss: 4511526.0000 - dense_299_loss: 24587.1836 - val_loss: 3555256.7500 - val_dense_296_loss: 3525633.2500 - val_dense_299_loss: 29623.2012\n",
      "Epoch 17/1000\n",
      "9/9 [==============================] - ETA: 0s - loss: 8522212.0000 - dense_296_loss: 8445257.0000 - dense_299_loss: 76954.796 - 0s 3ms/step - loss: 4020879.5000 - dense_296_loss: 3995105.2500 - dense_299_loss: 25774.5762 - val_loss: 3652017.0000 - val_dense_296_loss: 3627563.2500 - val_dense_299_loss: 24453.6562\n",
      "Epoch 18/1000\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3758879.5000 - dense_296_loss: 3734927.0000 - dense_299_loss: 23952.1797 - val_loss: 3884643.5000 - val_dense_296_loss: 3860876.5000 - val_dense_299_loss: 23767.2383\n",
      "Epoch 19/1000\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3710907.7500 - dense_296_loss: 3688936.2500 - dense_299_loss: 21971.8242 - val_loss: 3832197.5000 - val_dense_296_loss: 3801286.7500 - val_dense_299_loss: 30910.6230\n",
      "Epoch 20/1000\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3725120.0000 - dense_296_loss: 3692351.2500 - dense_299_loss: 32768.7109 - val_loss: 3748436.2500 - val_dense_296_loss: 3724850.5000 - val_dense_299_loss: 23585.6758\n",
      "Epoch 21/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 3706627.2500 - dense_296_loss: 3685607.5000 - dense_299_loss: 21019.4297 - val_loss: 3773221.5000 - val_dense_296_loss: 3743824.2500 - val_dense_299_loss: 29397.2383\n",
      "Epoch 22/1000\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3706135.5000 - dense_296_loss: 3683971.0000 - dense_299_loss: 22164.6055 - val_loss: 3862349.7500 - val_dense_296_loss: 3836149.2500 - val_dense_299_loss: 26200.5156\n",
      "Epoch 23/1000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 3709394.7500 - dense_296_loss: 3682357.5000 - dense_299_loss: 27036.9785 - val_loss: 3813212.7500 - val_dense_296_loss: 3791762.7500 - val_dense_299_loss: 21449.9961\n",
      "Epoch 24/1000\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3729629.2500 - dense_296_loss: 3706081.5000 - dense_299_loss: 23548.2969 - val_loss: 3704021.2500 - val_dense_296_loss: 3669921.7500 - val_dense_299_loss: 34099.5312\n",
      "Epoch 25/1000\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3746625.2500 - dense_296_loss: 3721497.7500 - dense_299_loss: 25127.3242 - val_loss: 3837246.0000 - val_dense_296_loss: 3812730.5000 - val_dense_299_loss: 24515.3105\n",
      "Epoch 26/1000\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3737102.7500 - dense_296_loss: 3714849.7500 - dense_299_loss: 22252.6562 - val_loss: 3870520.5000 - val_dense_296_loss: 3846322.0000 - val_dense_299_loss: 24198.7363\n",
      "Epoch 27/1000\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3721625.2500 - dense_296_loss: 3697318.0000 - dense_299_loss: 24307.2051 - val_loss: 3670523.7500 - val_dense_296_loss: 3648158.0000 - val_dense_299_loss: 22365.4102\n",
      "Epoch 28/1000\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3726975.7500 - dense_296_loss: 3703577.0000 - dense_299_loss: 23398.3223 - val_loss: 3788835.7500 - val_dense_296_loss: 3760706.7500 - val_dense_299_loss: 28128.7637\n",
      "Epoch 29/1000\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3689607.0000 - dense_296_loss: 3666573.0000 - dense_299_loss: 23034.2871 - val_loss: 3783435.5000 - val_dense_296_loss: 3758879.0000 - val_dense_299_loss: 24556.5742\n",
      "Epoch 30/1000\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3716483.2500 - dense_296_loss: 3693589.7500 - dense_299_loss: 22893.5391 - val_loss: 3726924.2500 - val_dense_296_loss: 3705205.7500 - val_dense_299_loss: 21718.6309\n",
      "Epoch 31/1000\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3711918.2500 - dense_296_loss: 3683873.2500 - dense_299_loss: 28044.8555 - val_loss: 3709309.0000 - val_dense_296_loss: 3687556.2500 - val_dense_299_loss: 21752.4258\n",
      "Epoch 32/1000\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3700152.7500 - dense_296_loss: 3678305.0000 - dense_299_loss: 21847.5723 - val_loss: 3821379.2500 - val_dense_296_loss: 3796957.7500 - val_dense_299_loss: 24421.2812\n",
      "Epoch 33/1000\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3703616.2500 - dense_296_loss: 3678126.5000 - dense_299_loss: 25489.5254 - val_loss: 3805550.5000 - val_dense_296_loss: 3780813.0000 - val_dense_299_loss: 24737.4688\n",
      "Epoch 34/1000\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3707046.0000 - dense_296_loss: 3682205.2500 - dense_299_loss: 24840.3223 - val_loss: 3735909.7500 - val_dense_296_loss: 3713525.0000 - val_dense_299_loss: 22384.8516\n",
      "Epoch 35/1000\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3703438.7500 - dense_296_loss: 3673982.7500 - dense_299_loss: 29455.6738 - val_loss: 3785717.0000 - val_dense_296_loss: 3764852.2500 - val_dense_299_loss: 20864.7266\n",
      "Epoch 36/1000\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3708031.7500 - dense_296_loss: 3686333.2500 - dense_299_loss: 21698.5742 - val_loss: 3739829.5000 - val_dense_296_loss: 3706961.2500 - val_dense_299_loss: 32868.1406\n",
      "Epoch 37/1000\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3741900.5000 - dense_296_loss: 3719767.5000 - dense_299_loss: 22132.7773 - val_loss: 3824560.5000 - val_dense_296_loss: 3803590.0000 - val_dense_299_loss: 20970.5312\n",
      "Epoch 38/1000\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3708950.5000 - dense_296_loss: 3686731.7500 - dense_299_loss: 22218.5547 - val_loss: 3726099.5000 - val_dense_296_loss: 3698882.7500 - val_dense_299_loss: 27216.5957\n",
      "Epoch 39/1000\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3773585.0000 - dense_296_loss: 3750031.0000 - dense_299_loss: 23554.0508 - val_loss: 3582960.0000 - val_dense_296_loss: 3553862.0000 - val_dense_299_loss: 29097.7793\n",
      "Epoch 40/1000\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3758274.7500 - dense_296_loss: 3735958.7500 - dense_299_loss: 22315.8965 - val_loss: 3785520.2500 - val_dense_296_loss: 3762465.7500 - val_dense_299_loss: 23054.4707\n",
      "Epoch 41/1000\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3729389.2500 - dense_296_loss: 3705528.5000 - dense_299_loss: 23860.6680 - val_loss: 3796151.0000 - val_dense_296_loss: 3769215.0000 - val_dense_299_loss: 26936.0684\n",
      "Epoch 42/1000\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3656926.5000 - dense_296_loss: 3635160.0000 - dense_299_loss: 21766.5000 - val_loss: 3657421.2500 - val_dense_296_loss: 3631704.5000 - val_dense_299_loss: 25716.8105\n",
      "Epoch 43/1000\n",
      "9/9 [==============================] - ETA: 0s - loss: 1451941.3750 - dense_296_loss: 1426241.3750 - dense_299_loss: 25700.013 - 0s 3ms/step - loss: 3723201.7500 - dense_296_loss: 3699624.7500 - dense_299_loss: 23577.2715 - val_loss: 3642213.5000 - val_dense_296_loss: 3617205.7500 - val_dense_299_loss: 25007.4492\n",
      "Epoch 44/1000\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3674906.7500 - dense_296_loss: 3652751.5000 - dense_299_loss: 22155.0605 - val_loss: 3715093.0000 - val_dense_296_loss: 3690794.5000 - val_dense_299_loss: 24298.3691\n",
      "Epoch 45/1000\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3713548.5000 - dense_296_loss: 3691307.5000 - dense_299_loss: 22241.4688 - val_loss: 3724808.0000 - val_dense_296_loss: 3701613.0000 - val_dense_299_loss: 23194.7930\n",
      "Epoch 46/1000\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 3672230.0000 - dense_296_loss: 3649791.7500 - dense_299_loss: 22438.4023 - val_loss: 3750564.2500 - val_dense_296_loss: 3719593.2500 - val_dense_299_loss: 30971.1465\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "es = EarlyStopping(monitor='val_loss', mode='auto', patience=30, restore_best_weights=True)\n",
    "hist = model.fit([x1_train,x2_train], [y1_train, y2_train], epochs=1000, batch_size=1,\n",
    "                 validation_split=0.3, callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "평가 & 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 233ms/step - loss: 5530529.0000 - dense_296_loss: 5500304.5000 - dense_299_loss: 30224.3477\n",
      "loss :  [5530529.0, 5500304.5, 30224.34765625]\n",
      "예측값 :  [9924504.] [26546.514]\n"
     ]
    }
   ],
   "source": [
    "loss = model.evaluate([x1_test, x2_test], [y1_test, y2_test])\n",
    "print('loss : ', loss)\n",
    "ss_pred, ki_pred = model.predict([x1_test, x2_test])\n",
    "print('예측값 : ', ss_pred[-1], ki_pred[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../_save/stock_tue_vol_{}.h5\".format(ss_pred[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = hist.history[\"loss\"]\n",
    "ss_loss = hist.history[\"dense_296_loss\"]\n",
    "ku_loss = hist.history[\"dense_299_loss\"]\n",
    "ss_val = hist.history[\"val_dense_296_loss\"]\n",
    "ku_val = hist.history[\"val_dense_299_loss\"]\n",
    "\n",
    "epochs = range(1, len(loss)+1)\n",
    "\n",
    "plt.plot(epochs, loss, 'y--', label=\"training loss\")\n",
    "plt.plot(epochs, ss_loss, 'r--', label=\"ss_loss\")\n",
    "plt.plot(epochs, ku_loss, 'b--', label=\"ku_loss\")\n",
    "plt.plot(epochs, ss_val, 'r:', label=\"ss_val\")\n",
    "plt.plot(epochs, ku_val, 'b:', label=\"ku_val\")\n",
    "\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1318 test_function  *\n        return step_function(self, iterator)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1309 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1302 run_step  **\n        outputs = model.test_step(data)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1261 test_step\n        y_pred = self(x, training=False)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1013 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:267 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) +\n\n    ValueError: Input 0 is incompatible with layer model_16: expected shape=(None, 4, 1), found shape=(None, 3, 2)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7044/3203367396.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../_save/stock_mon_cp_[77204.89].h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx1_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx2_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0my1_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my2_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'loss : '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mss_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mki_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx1_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx2_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1482\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1483\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1484\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1485\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1486\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 763\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    764\u001b[0m             *args, **kwds))\n\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3049\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3050\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3051\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3444\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3277\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3278\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3279\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3280\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3281\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 999\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    984\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1318 test_function  *\n        return step_function(self, iterator)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1309 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1302 run_step  **\n        outputs = model.test_step(data)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1261 test_step\n        y_pred = self(x, training=False)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1013 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:267 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) +\n\n    ValueError: Input 0 is incompatible with layer model_16: expected shape=(None, 4, 1), found shape=(None, 3, 2)\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"../_save/stock_tue_vol_[77204.89].h5\")\n",
    "\n",
    "loss = model.evaluate([x1_test, x2_test], [y1_test, y2_test])\n",
    "print('loss : ', loss)\n",
    "ss_pred, ki_pred = model.predict([x1_test, x2_test])\n",
    "print('예측값 : ', ss_pred[-1], ki_pred[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
