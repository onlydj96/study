{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "오디오 분류(Audio Classification)\n",
    "=====================================\n",
    "\n",
    "    - 가상 악기를 활용해 악기별 음색 데이터셋을 활용해 오디오 분류\n",
    "       1. 기존 데이터에서 분류에 사용되는 방법을 사용해 분류\n",
    "       2. 오디어 데이터에 특화된 분류\n",
    "    - 출처 : https://bab2min.tstory.com/642"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 준비 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import librosa\n",
    "import librosa.display \n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - 데이터를 저장할 리스트와 파일을 불러올 경로를 지정\n",
    "   - https://www.dropbox.com/s/3dsnj5ldtf3dcx4/GeneralMidi.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_file = 'C:/Users/user/Desktop/Python/dataset/Audio_Files/Major.wav'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - wmv 파일에는 128개 악기와 46개 타악기의 음을 50개씩 2초 간격으로 존재\n",
    "   - 해당 예제에서는 일부 악기만 선택해서 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'itertools' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-fbe1107598ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0maudio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0minst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0minst_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnote\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstruments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_notes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0minstrument\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minstruments\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minst_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0moffset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minstrument\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnum_notes\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msec\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnote\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'itertools' is not defined"
     ]
    }
   ],
   "source": [
    "instruments = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "num_notes = 50\n",
    "sec = 2\n",
    "\n",
    "audio = []\n",
    "inst = []\n",
    "for inst_idx, note in itertools.product(range(len(instruments)), range(num_notes)):\n",
    "    instrument = instruments[inst_idx]\n",
    "    offset = (instrument*num_notes*sec + (note*sec))\n",
    "    print('instrument : {}, note: {}, offset : {}'.format(instrument, note, offset))\n",
    "    y, sr = librosa.load(midi_file, sr=None, offset=offset, duration=2.0)\n",
    "    audio.append(y)\n",
    "    inst.append(inst_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_np = np.array(audio, np.float32)\n",
    "inst_np = np.array(inst, np.int16)\n",
    "\n",
    "print(audio_np.shape, inst_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(0, len(audio_np), num_notes):\n",
    "    plt.figure(figsize=(18, 2))\n",
    "    plt.plot(audio_np[idx])\n",
    "    plt.ylim((-0.05, 0.05))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫번째 악기 소리\n",
    "print(inst_np[0])\n",
    "ipd.Audio(audio_np[0], rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세번째 악기 소리\n",
    "print(inst_np[100])\n",
    "ipd.Audio(audio_np[100], rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(audio_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "머신러닝을 이용한 오디오 분류\n",
    "   - 학습 데이터와 실험 데이터를 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(audio_np, inst_np, test_size=0.2)\n",
    "\n",
    "print(train_x.shape)\n",
    "print(test_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression\n",
    "   - Logistic Regression은 특성상 다중 분류에는 적합하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "LR = LogisticRegression()\n",
    "LR.fit(train_x, train_y)\n",
    "pred = LR.predict(test_x)\n",
    "acc = accuracy_score(pred, test_y)\n",
    "print(accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "SVM = svm.SVC(kernel='linear')\n",
    "SVM.fit(train_x, train_y)\n",
    "pred = SVM.predict(test_x)\n",
    "acc = accuracy_score(pred, test_y)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "DT = DecisionTreeClassifier()\n",
    "DT.fit(train_x, train_y)\n",
    "pred = DT.predict(test_x)\n",
    "acc = accuracy_score(pred, test_y)\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
