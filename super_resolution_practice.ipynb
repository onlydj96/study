{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_images(path, factor):\n",
    "    \n",
    "    # loop through the file in the directory \n",
    "    for file in os.listdir(path):\n",
    "        img = cv2.imread(path + '/' + file)\n",
    "        \n",
    "        # find old and new image dimensions\n",
    "        h, w, c = img.shape\n",
    "        new_height = int(h / factor)\n",
    "        new_width = int(w / factor)\n",
    "        \n",
    "        # resize the image - down\n",
    "        img = cv2.resize(img, (new_width, new_height), interpolation = cv2.INTER_LINEAR)\n",
    "        \n",
    "        # resize the image - up\n",
    "        img = cv2.resize(img, (w, h), interpolation = cv2.INTER_LINEAR)\n",
    "        \n",
    "        # save the image\n",
    "        print('Saving {}'.format(file))\n",
    "        cv2.imwrite('./images/{}'.format(file), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving baboon.bmp\n",
      "Saving barbara.bmp\n",
      "Saving bridge.bmp\n",
      "Saving coastguard.bmp\n",
      "Saving comic.bmp\n",
      "Saving face.bmp\n",
      "Saving flowers.bmp\n",
      "Saving foreman.bmp\n",
      "Saving lenna.bmp\n",
      "Saving man.bmp\n",
      "Saving monarch.bmp\n",
      "Saving pepper.bmp\n",
      "Saving ppt3.bmp\n",
      "Saving zebra.bmp\n"
     ]
    }
   ],
   "source": [
    "prepare_images('./source', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_data(path):\n",
    "    names = os.listdir(path)   # 100개의 데이터를 순서대로 불러오기\n",
    "    names = sorted(names)       # 100개의 데이터가 순서대로 정리\n",
    "    nums = names.__len__()      # 100\n",
    "    data = []\n",
    "    for i in range(nums):\n",
    "        name = path + names[i]\n",
    "        img = cv2.imread(name)\n",
    "        data.append(img)\n",
    "    return data\n",
    "    # for file in os.listdir(path):\n",
    "    #     target = []\n",
    "    #     img = cv2.imread(path + '/' + file)\n",
    "    #     target.append(img)\n",
    "    # return np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = image_data('./source/')\n",
    "y = image_data('./images/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 500, 3) (480, 500, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x[0].shape, y[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modcrop(img, scale):\n",
    "    tmpsz = img.shape\n",
    "    sz = tmpsz[0:2]\n",
    "    sz = sz - np.mod(sz, scale)\n",
    "    img = img[0:sz[0], 0:sz[1]]\n",
    "    return img\n",
    "\n",
    "def shave(image, border):\n",
    "    img = image[border:-border, border:-border]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BLOCK_STEP = 16\n",
    "BLOCK_SIZE = 32\n",
    "Random_Crop = 30\n",
    "Patch_size = 32\n",
    "label_size = 20\n",
    "conv_side = 6\n",
    "\n",
    "def prepare_crop_data(_path):\n",
    "    names = os.listdir(_path)\n",
    "    names = sorted(names)\n",
    "    nums = names.__len__()\n",
    "\n",
    "    data = []\n",
    "    label = []\n",
    "\n",
    "    for i in range(nums):\n",
    "        name = _path + names[i]\n",
    "        hr_img = cv2.imread(name, cv2.IMREAD_COLOR)\n",
    "        hr_img = cv2.cvtColor(hr_img, cv2.COLOR_BGR2YCrCb)\n",
    "        hr_img = hr_img[:, :, 0]\n",
    "        shape = hr_img.shape\n",
    "        \n",
    "        scale = 2\n",
    "        w, h, = hr_img.shape\n",
    "        new_width = int(w / scale)\n",
    "        new_height = int(h / scale)\n",
    "        \n",
    "        lr_img = cv2.resize(hr_img, (new_width, new_height))\n",
    "        lr_img = cv2.resize(lr_img, (shape[1], shape[0]))\n",
    "\n",
    "        width_num = (shape[0] - (BLOCK_SIZE - BLOCK_STEP) * 2) / BLOCK_STEP\n",
    "        height_num = (shape[1] - (BLOCK_SIZE - BLOCK_STEP) * 2) / BLOCK_STEP\n",
    "        for k in range(width_num):\n",
    "            for j in range(height_num):\n",
    "                x = k * BLOCK_STEP\n",
    "                y = j * BLOCK_STEP\n",
    "                hr_patch = hr_img[x: x + BLOCK_SIZE, y: y + BLOCK_SIZE]\n",
    "                lr_patch = lr_img[x: x + BLOCK_SIZE, y: y + BLOCK_SIZE]\n",
    "\n",
    "                lr_patch = lr_patch.astype(float) / 255.\n",
    "                hr_patch = hr_patch.astype(float) / 255.\n",
    "\n",
    "                lr = np.zeros((1, Patch_size, Patch_size), dtype=np.double)\n",
    "                hr = np.zeros((1, label_size, label_size), dtype=np.double)\n",
    "\n",
    "                lr[0, :, :] = lr_patch\n",
    "                hr[0, :, :] = hr_patch[conv_side: -conv_side, conv_side: -conv_side]\n",
    "\n",
    "                data.append(lr)\n",
    "                label.append(hr)\n",
    "\n",
    "    data = np.array(data, dtype=float)\n",
    "    label = np.array(label, dtype=float)\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15904/3044996011.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdatasets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepare_crop_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'HR/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# label = datasets[1]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15904/198380697.py\u001b[0m in \u001b[0;36mprepare_crop_data\u001b[1;34m(_path)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mwidth_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mBLOCK_SIZE\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mBLOCK_STEP\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mBLOCK_STEP\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mheight_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mBLOCK_SIZE\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mBLOCK_STEP\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mBLOCK_STEP\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidth_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheight_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mBLOCK_STEP\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "datasets = prepare_crop_data('HR/')\n",
    "\n",
    "datasets[0].shape\n",
    "# label = datasets[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384, 384, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRCNN = Sequential()\n",
    "    \n",
    "# add model layers\n",
    "SRCNN.add(Conv2D(filters=128, kernel_size=(9, 9), kernel_initializer='glorot_uniform',\n",
    "                     activation='relu', padding='valid', use_bias=True, input_shape=(None, None, 1)))\n",
    "SRCNN.add(Conv2D(filters=64, kernel_size=(3, 3), kernel_initializer='glorot_uniform',\n",
    "                     activation='relu', padding='same', use_bias=True))\n",
    "SRCNN.add(Conv2D(filters=1, kernel_size=(5,5), kernel_initializer='glorot_uniform',\n",
    "                     activation='linear', padding='valid', use_bias=True))\n",
    "    \n",
    "# compile model\n",
    "SRCNN.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "SRCNN.fit(data, label, batch_size=10, validation_data=(val_data, val_label), epochs=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 500, 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_img = cv2.imread('./source/baboon.bmp')\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
