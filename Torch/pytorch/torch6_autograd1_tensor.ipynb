{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUTOGRAD(자동미분)\n",
    "   - autograd 패키지는 Tensor의 모든 연산에 대해 자동 미분 제공\n",
    "   - 이는 코드를 어떻게 작성하여 실행하느냐에 따라 역전파가 정의된다는 뜻\n",
    "   - backprop를 위한 미분값을 자동으로 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor \n",
    "   - data: tensor형태의 데이터\n",
    "   - grad : data가 거쳐온 layer에 대한 미분값 저장 \n",
    "   - grad_fn: 미분값을 계산한 함수에 대한 정보 저장 (어떤 함수에 대해서 backprop 했는지)\n",
    "   - requires_grad 속성을 True로 설정하면, 해당 텐서에서 이루어지는 모든 연산들을 추적하기 시작\n",
    "   - 계산이 완료된 후, .backward()를 호출하면 자동으로 gradient를 계산할 수 있으며, .grad 속성에 누적됨\n",
    "   - 기록을 추적하는 것을 중단하게 하려면, .detach()를 호출하여 연산기록으로 분리\n",
    "   - 기록을 추적하는 것을 방지하기 위해 코드 블럭을 with torch.no_grad():로 감싸면 gradient는 필요없지만, requires_grad=True로 설정되어 \n",
    "     학습가능 한 매개변수를 갖는 모델을 평가(evaluate)할 때 유용\n",
    "   - autograd 구현에서 매우 중요한 클래스 : Fuction 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(3, 3, requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x + 5  # \n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = y * y * 2\n",
    "out = z.mean()\n",
    "\n",
    "print(z, out)  # grad_fn에 연산 정보가 저장?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - requires_grad_(...)는 기존 텐서의 requires_grad값을 바꿔치기(in_place)하여 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(3, 3)\n",
    "a = ((a * 3) / (a - 1))\n",
    "print(a.requires_grad)\n",
    "\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)\n",
    "\n",
    "b = (a * a).sum()\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b69a98d3df882577ba469635c4ab08c5ae67eaedfd3a57f311f98966a6edb2d0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('torch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
